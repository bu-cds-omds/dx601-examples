{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XwztbsYFtAk"
      },
      "source": [
        "# Video: Matrix Multiplication in Neural Networks\n",
        "\n",
        "This video explains the role of matrix multiplication, a fundamental operation in linear algebra, in neural network implementations.\n",
        "Matrix multiplication plays a key part in the evaluation of neural networks, and in understanding how they work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id_829746799654-header"
      },
      "source": [
        "## Neural Networks Introduction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_nodes(x, ys, label, name_format=None):\n",
        "    plt.plot([x for _ in ys], ys, label=label, linestyle=\"none\", marker=\"o\")\n",
        "\n",
        "    if name_format:\n",
        "        for (i, y) in enumerate(ys):\n",
        "            plt.annotate(name_format.format(i), (x, y + 2))\n",
        "\n",
        "def connect(x1, y1, x2, y2, label=None):\n",
        "    plt.arrow(x1, y1, x2-x1, y2-y1,\n",
        "              color=\"grey\",\n",
        "              head_width=2.0,\n",
        "              length_includes_head=True)\n",
        "\n",
        "    if label:\n",
        "        x_mid = x1 + (x2 - x1) / 4\n",
        "        y_mid = y1 + (y2 - y1) / 4\n",
        "        plt.annotate(label, (x_mid, y_mid + (2 if y2 < y1 else -3)))\n",
        "\n",
        "def finish_network():\n",
        "    plt.gca().set_xlim(0, 100)\n",
        "    plt.gca().set_ylim(0, 100)\n",
        "    plt.gca().xaxis.set_visible(False)\n",
        "    plt.gca().yaxis.set_visible(False)\n",
        "    plt.legend()\n",
        "\n",
        "input_x = 20\n",
        "input_ys = [33, 67]\n",
        "output_x = 80\n",
        "output_y = 50\n",
        "\n",
        "plot_nodes(input_x, input_ys, \"input\", \"$input_{0}$\")\n",
        "plot_nodes(output_x, [output_y], \"output\", \"$output$\")\n",
        "\n",
        "for (i, input_y) in enumerate(input_ys):\n",
        "    connect(input_x, input_y, output_x, output_y, label=f\"$weight_{i}$\")\n",
        "\n",
        "plt.title('\"Neuron\" Output is a Function of Inputs and Weights')\n",
        "plt.annotate(\"$output = f(input_0 * weight_0 + input_1 * weight_1)$\", (35, 20))\n",
        "finish_network()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id_279550578554-header"
      },
      "source": [
        "## Neural Networks in General\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_x = 10\n",
        "input_ys = [33, 67]\n",
        "\n",
        "hidden_xs = [35, 55]\n",
        "hidden_ys = [20, 50, 80]\n",
        "\n",
        "output_x = 90\n",
        "output_y = 50\n",
        "\n",
        "plot_nodes(input_x, input_ys, \"input\")\n",
        "for hidden_x in hidden_xs:\n",
        "    plot_nodes(hidden_x, hidden_ys, \"\")\n",
        "plot_nodes(output_x, [output_y], \"output\")\n",
        "\n",
        "connect(input_x, input_ys[0], hidden_xs[0], hidden_ys[0])\n",
        "connect(input_x, input_ys[0], hidden_xs[0], hidden_ys[1])\n",
        "connect(input_x, input_ys[1], hidden_xs[0], hidden_ys[1])\n",
        "connect(input_x, input_ys[1], hidden_xs[0], hidden_ys[2])\n",
        "connect(hidden_xs[0], hidden_ys[0], hidden_xs[1], hidden_ys[0])\n",
        "connect(hidden_xs[0], hidden_ys[0], hidden_xs[1], hidden_ys[1])\n",
        "connect(hidden_xs[0], hidden_ys[1], hidden_xs[1], hidden_ys[1])\n",
        "connect(hidden_xs[0], hidden_ys[1], hidden_xs[1], hidden_ys[2])\n",
        "connect(hidden_xs[0], hidden_ys[2], hidden_xs[1], hidden_ys[2])\n",
        "connect(hidden_xs[0], hidden_ys[2], output_x, output_y)\n",
        "\n",
        "for hidden_y in hidden_ys:\n",
        "    connect(hidden_xs[-1], hidden_y, output_x, output_y)\n",
        "\n",
        "plt.title(\"Neural Networks can Have Arbitrary Connections\")\n",
        "finish_network()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id_148398498057-header"
      },
      "source": [
        "## Neural Networks in Practice\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_fully_connected(x1, y1s, x2, y2s, label_format=None):\n",
        "    for (i, y1) in enumerate(y1s):\n",
        "        for (j, y2) in enumerate(y2s):\n",
        "            connect(x1, y1, x2, y2,\n",
        "                    label=label_format.format(i, j) if label_format else None)\n",
        "\n",
        "input_x = 20\n",
        "hidden_xs = [40, 60]\n",
        "output_x = 80\n",
        "\n",
        "input_ys = [33, 67]\n",
        "hidden_ys = range(15, 86, 10)\n",
        "output_ys = [50]\n",
        "\n",
        "plot_fully_connected(input_x, input_ys, hidden_xs[0], hidden_ys)\n",
        "plot_fully_connected(hidden_xs[0], hidden_ys, hidden_xs[1], hidden_ys)\n",
        "plot_fully_connected(hidden_xs[1], hidden_ys, output_x, output_ys)\n",
        "\n",
        "plot_nodes(input_x, input_ys, \"input\")\n",
        "for (i, hidden_x) in enumerate(hidden_xs):\n",
        "    plot_nodes(hidden_x, hidden_ys, f\"hidden {i+1}\")\n",
        "plot_nodes(output_x, output_ys, \"output\")\n",
        "\n",
        "finish_network()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id_700843813276-header"
      },
      "source": [
        "## Universal Approximation Theorem\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_x = 20\n",
        "hidden_x = 50\n",
        "output_x = 80\n",
        "\n",
        "input_ys = [33, 67]\n",
        "hidden_ys = range(1, 100, 1)\n",
        "output_ys = [50]\n",
        "\n",
        "plot_fully_connected(input_x, input_ys, hidden_x, hidden_ys)\n",
        "plot_fully_connected(hidden_x, hidden_ys, output_x, output_ys)\n",
        "\n",
        "plot_nodes(input_x, input_ys, \"input\")\n",
        "plot_nodes(hidden_x, hidden_ys, \"hidden\")\n",
        "plot_nodes(output_x, output_ys, \"output\")\n",
        "\n",
        "plt.title(\"Approximate Any Function with One Huge Hidden Layer\")\n",
        "finish_network()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id_331855995393-header"
      },
      "source": [
        "## Matrix Multiplication in Neural Networks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_x = 10\n",
        "hidden_x = 50\n",
        "output_x = 90\n",
        "\n",
        "input_ys = [33, 67]\n",
        "hidden_ys = range(15, 86, 35)\n",
        "output_ys = [50]\n",
        "\n",
        "plot_fully_connected(input_x, input_ys, hidden_x, hidden_ys, \"$w_{{{0},{1}}}$\")\n",
        "plot_fully_connected(hidden_x, hidden_ys, output_x, output_ys, \"$v_{{{0},{1}}}$\")\n",
        "\n",
        "plot_nodes(input_x, input_ys, \"input\", \"$i_{0}$\")\n",
        "plot_nodes(hidden_x, hidden_ys, \"hidden\", \"$h_{0}$\")\n",
        "plot_nodes(output_x, output_ys, \"output\", \"$output$\")\n",
        "\n",
        "plt.annotate(\"$h_{j} = f(i_0 w_{0,j} + i_1 w_{1,j})$\\n$\\\\mathbf{h}=f(\\\\mathbf{i} \\\\mathbf{W})$\", (5, 5))\n",
        "plt.annotate(\"$output_0 = f(h_0 v_{0,0} + h_1 v_{1,0})$\\n$\\\\mathbf{output} = f(\\\\mathbf{h} \\\\mathbf{V})$\", (55, 5))\n",
        "\n",
        "finish_network()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZAQ42t_TmbR"
      },
      "source": [
        "## Matrix Multiplication for One Neuron\n",
        "\n",
        "\\begin{array}{rcl}\n",
        "o_{i,j} & = &\n",
        "f\\left(\n",
        "    \\begin{bmatrix}\n",
        "    o_{i-1,0} &\n",
        "    \\ldots &\n",
        "    o_{i-1,n-1} \\\\\n",
        "    \\end{bmatrix}\n",
        "    \\begin{bmatrix}\n",
        "    w_{0,j} \\\\\n",
        "    w_{1,j} \\\\\n",
        "    \\ldots \\\\\n",
        "    w_{n-1,j} \\\\\n",
        "    \\end{bmatrix}\n",
        "    \\right) \\\\\n",
        "\\end{array}\n",
        "\n",
        "$f$ is the activation function of the neuron."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwW03FzfRB8t"
      },
      "source": [
        "## Matrix Multiplication for One Layer\n",
        "\n",
        "\\begin{array}{rcl}\n",
        "\\begin{bmatrix}\n",
        "x_{i,0} & \\ldots & x_{i,n-1} \\\\\n",
        "\\end{bmatrix}\n",
        "& = &\n",
        "f\\left(\n",
        "    \\begin{bmatrix}\n",
        "    x_{i-1,0} &\n",
        "    \\ldots &\n",
        "    x_{i-1,n-1} \\\\\n",
        "    \\end{bmatrix}\n",
        "    \\begin{bmatrix}\n",
        "    w_{0,0} & \\ldots & w_{0,n-1} \\\\\n",
        "    w_{1,0} & \\ldots & w_{0,n-1} \\\\\n",
        "    \\ldots \\\\\n",
        "    w_{n-1,0} & \\ldots & w_{n-1,n-1} \\\\\n",
        "    \\end{bmatrix}\n",
        "    \\right) \\\\\n",
        "\\end{array}\n",
        "\n",
        "Activation function $f$ is applied element-wise to the output of the matrix multiplication."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z--oMzgkHa2n"
      },
      "source": [
        "## Neural Networks Oversimplified\n",
        "\n",
        "\\begin{array}{rcl}\n",
        "\\mathbf{x_0} & = & \\mathbf{X} \\\\\n",
        "\\mathbf{x_1} & = & f(\\mathbf{x_1 W_1} + \\mathbf{b_1}) \\\\\n",
        "\\mathbf{x_2} & = & f(\\mathbf{x_2 W_2} + \\mathbf{b_2}) \\\\\n",
        "\\mathbf{x_3} & = & f(\\mathbf{x_3 W_3} + \\mathbf{b_3}) \\\\\n",
        "...\n",
        "\\end{array}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lyQY5ykW35p"
      },
      "source": [
        "## Matrix Multiplication as an Information Bottleneck\n",
        "\n",
        "Information in the inputs might be lost when multiplying by an $m \\times n$ matrix $\\mathbf{W}$ if\n",
        "* $n < m$\n",
        "* $\\mathbf{W}$ is low rank\n",
        "* $\\mathbf{W}$ is not invertible\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {},
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}